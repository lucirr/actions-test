apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "sklearn-iris"
  namespace: ${namespace}
spec:
  predictor:
    model:
      modelFormat:
        name: sklearn
      storageUri: "s3://mlflow-artifacts/models/my-ml-model/${modelVersion}"
      resources:
        requests:
          cpu: 100m
          memory: 256Mi
        limits:
          cpu: 100m
          memory: 256Mi
    canaryTrafficPercent: ${canaryPercent}      